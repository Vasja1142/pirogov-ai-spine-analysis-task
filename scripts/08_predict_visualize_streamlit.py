"""
Streamlit-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏ YOLOv8 Segmentation
–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∏—Ö —Å –∏—Å—Ç–∏–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏ (Ground Truth).

–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–∂–µ—Ç:
- –ó–∞–≥—Ä—É–∂–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.
- –ü–µ—Ä–µ–∫–ª—é—á–∞—Ç—å—Å—è –º–µ–∂–¥—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏.
- –ü—Ä–æ—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –∏—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
streamlit run scripts/08_predict_visualize_streamlit.py -- \
--model-path data/05_runs/spine_segmentation_v2/weights/best.pt \
--image-dir data/04_normalized/test/images
"""

import streamlit as st
import cv2
import numpy as np
from pathlib import Path
from ultralytics import YOLO
import argparse
from typing import List, Optional, Tuple

st.set_page_config(layout="wide", page_title="YOLOv8 Segmentation Visualizer")
st.title("ü©ª YOLOv8 Segmentation Visualizer")
st.markdown("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏ —Å –∏—Å—Ç–∏–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏.")

# ============================================================================
# ‚öôÔ∏è –§–£–ù–ö–¶–ò–ò –ó–ê–ì–†–£–ó–ö–ò –î–ê–ù–ù–´–• –ò –ú–û–î–ï–õ–ò
# ============================================================================

def load_image_paths(image_directory: Path) -> List[Path]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫–æ –≤—Å–µ–º –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏."""
    if not image_directory.is_dir():
        st.error(f"–û—à–∏–±–∫–∞: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {image_directory}")
        return []
    extensions = ["*.jpg", "*.jpeg", "*.png", "*.bmp", "*.tif"]
    image_paths = sorted([p for ext in extensions for p in image_directory.glob(ext)])
    if not image_paths:
        st.warning(f"–í –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {image_directory} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.")
    return image_paths

def load_yolo_model(model_path: Path) -> Optional[YOLO]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å YOLOv8 –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ø—É—Ç–∏."""
    if not model_path.is_file():
        st.error(f"–û—à–∏–±–∫–∞: –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {model_path}")
        return None
    try:
        model = YOLO(str(model_path))
        return model
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ YOLO: {e}")
        return None

# ============================================================================
# üé® –§–£–ù–ö–¶–ò–ò –û–¢–†–ò–°–û–í–ö–ò
# ============================================================================

def get_ground_truth_and_draw(img_path: Path, original_image: np.ndarray) -> Optional[np.ndarray]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–µ—Ç–∫–∏ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –æ—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ—Ç –∏—Ö.

    Args:
        img_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
        original_image: –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ NumPy array.

    Returns:
        –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –æ—Ç—Ä–∏—Å–æ–≤–∞–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏ –∏–ª–∏ None, –µ—Å–ª–∏ –º–µ—Ç–æ–∫ –Ω–µ—Ç.
    """
    # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ labels –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –Ω–∞ –¥–≤–∞ —É—Ä–æ–≤–Ω—è –≤—ã—à–µ images (–≤ ../../labels/split/)
    # –ù–∞–ø—Ä–∏–º–µ—Ä: data/04_normalized/test/images/img.jpg -> data/04_normalized/test/labels/img.txt
    label_path = img_path.parents[1] / "labels" / f"{img_path.stem}.txt"

    if not label_path.is_file():
        return None # –ù–µ—Ç —Ñ–∞–π–ª–∞ —Ä–∞–∑–º–µ—Ç–∫–∏

    gt_image = original_image.copy()
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ, –¥–ª—è –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ —Ü–≤–µ—Ç–Ω—ã—Ö –ø–æ–ª–∏–≥–æ–Ω–æ–≤
    if gt_image.ndim == 2 or gt_image.shape[2] == 1: # Grayscale
        gt_image = cv2.cvtColor(gt_image, cv2.COLOR_GRAY2RGB)
    else: # BGR (OpenCV default)
        gt_image = cv2.cvtColor(gt_image, cv2.COLOR_BGR2RGB)

    h, w = gt_image.shape[:2]
    has_labels = False

    try:
        with open(label_path, "r") as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) < 2: continue

                # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —Ñ–æ—Ä–º–∞—Ç YOLO: class_id x_c y_c w h (–¥–ª—è bbox) –∏–ª–∏ class_id x1 y1 x2 y2 ... (–¥–ª—è poly)
                coords = np.array([float(x) for x in parts[1:]]).reshape(-1, 2)
                coords[:, 0] *= w
                coords[:, 1] *= h
                points = coords.astype(np.int32)

                # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ –ø–æ–ª–∏–≥–æ–Ω–∞
                cv2.polylines(gt_image, [points], isClosed=True, color=(0, 255, 0), thickness=2)
                has_labels = True
    except Exception as e:
        st.warning(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∏–ª–∏ –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ —Ñ–∞–π–ª–∞ —Ä–∞–∑–º–µ—Ç–∫–∏ {label_path.name}: {e}")
        return None

    return gt_image if has_labels else None

def display_images(
    original_rgb: np.ndarray,
    gt_rgb: Optional[np.ndarray],
    pred_rgb: np.ndarray,
    img_name: str,
    current_index: int,
    total_images: int
):
    """
    –û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç —Ç—Ä–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–æ—Ä–∏–≥–∏–Ω–∞–ª, GT, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ) –≤ Streamlit.
    """
    st.subheader(f"–§–∞–π–ª: {img_name} [{current_index + 1}/{total_images}]")

    cols = st.columns(3)

    with cols[0]:
        st.image(original_rgb, caption="–û—Ä–∏–≥–∏–Ω–∞–ª", use_column_width=True)
    with cols[1]:
        if gt_rgb is not None:
            st.image(gt_rgb, caption="–†–∞–∑–º–µ—Ç–∫–∞ (Manual GT)", use_column_width=True)
        else:
            st.markdown("<div style='text-align: center; color: gray;'>–ù–µ—Ç —Ñ–∞–π–ª–∞ —Ä–∞–∑–º–µ—Ç–∫–∏</div>", unsafe_allow_html=True)
            st.caption("–†–∞–∑–º–µ—Ç–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
    with cols[2]:
        st.image(pred_rgb, caption="–†–µ–∑—É–ª—å—Ç–∞—Ç –ú–æ–¥–µ–ª–∏", use_column_width=True)

# ============================================================================
# üöÄ –û–°–ù–û–í–ù–ê–Ø –õ–û–ì–ò–ö–ê STREAMLIT
# ============================================================================

def main():
    parser = argparse.ArgumentParser(description="YOLOv8 Segmentation Visualizer.")
    parser.add_argument(
        "--model-path",
        type=Path,
        default=Path("data/05_runs/spine_segmentation_v2/weights/best.pt"),
        help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ YOLO (–Ω–∞–ø—Ä–∏–º–µ—Ä, best.pt)."
    )
    parser.add_argument(
        "--image-dir",
        type=Path,
        default=Path("data/04_normalized/test/images"),
        help="–ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏."
    )
    # –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã streamlit run —Å –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏
    # https://docs.streamlit.io/library/advanced-features/command-line-options
    args = parser.parse_args()

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è Streamlit
    if "image_paths" not in st.session_state:
        st.session_state.image_paths = load_image_paths(args.image_dir)
        st.session_state.current_index = 0
    if "model" not in st.session_state:
        st.session_state.model = load_yolo_model(args.model_path)

    image_paths = st.session_state.image_paths
    model = st.session_state.model

    if not image_paths or model is None:
        st.stop()

    total_images = len(image_paths)
    current_index = st.session_state.current_index
    img_path = image_paths[current_index]

    # --- –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å –¥–ª—è –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ ---
    st.sidebar.header("–ù–∞–≤–∏–≥–∞—Ü–∏—è")
    col1, col2 = st.sidebar.columns(2)

    with col1:
        if st.button("‚¨ÖÔ∏è –ü—Ä–µ–¥—ã–¥—É—â–µ–µ", key="prev_img"):
            st.session_state.current_index = (current_index - 1 + total_images) % total_images
            st.experimental_rerun()
    with col2:
        if st.button("–°–ª–µ–¥—É—é—â–µ–µ ‚û°Ô∏è", key="next_img"):
            st.session_state.current_index = (current_index + 1) % total_images
            st.experimental_rerun()

    st.sidebar.write(f"–¢–µ–∫—É—â–µ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {current_index + 1} –∏–∑ {total_images}")

    # --- –û—Å–Ω–æ–≤–Ω–∞—è –æ–±–ª–∞—Å—Ç—å –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è ---
    original_img = cv2.imread(str(img_path))
    if original_img is None:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {img_path.name}")
        return
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è (Streamlit –æ–∂–∏–¥–∞–µ—Ç RGB)
    if original_img.ndim == 2 or original_img.shape[2] == 1:
        original_rgb = cv2.cvtColor(original_img, cv2.COLOR_GRAY2RGB)
    else:
        original_rgb = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)

    # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏
    results = model(original_img, retina_masks=True, verbose=False, conf=0.25)
    pred_plot = results[0].plot(boxes=False, conf=True)
    pred_rgb = cv2.cvtColor(pred_plot, cv2.COLOR_BGR2RGB)

    # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏ –æ—Ç—Ä–∏—Å–æ–≤–∫–∞ Ground Truth
    gt_rgb = get_ground_truth_and_draw(img_path, original_img)

    display_images(
        original_rgb, gt_rgb, pred_rgb, img_path.name, current_index, total_images
    )

if __name__ == "__main__":
    main()
