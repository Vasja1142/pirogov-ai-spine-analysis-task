"""
–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ (–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏) –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–≤–∞ —Ä–µ–∂–∏–º–∞ —Ä–∞–±–æ—Ç—ã:
1.  `dataset`: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–æ—Ä–º–∞—Ç–µ YOLO
    (–Ω–∞–ø—Ä–∏–º–µ—Ä, `train/images`, `train/labels`). –ú–µ—Ç–∫–∏ (`.txt`) –∫–æ–ø–∏—Ä—É—é—Ç—Å—è
    –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.
2.  `flat`: –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏,
    —Å–æ—Ö—Ä–∞–Ω—è—è —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–æ–¥–ø–∞–ø–æ–∫. –ú–µ—Ç–∫–∏ –∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç—Å—è.

–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
- –î–ª—è –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö YOLO:
  `python 04_normalize_data.py --mode dataset --input data/01_raw --output data/02_normalized`
- –î–ª—è –ø–∞–ø–∫–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏:
  `python 04_normalize_data.py --mode flat --input /path/to/images --output /path/to/output`
"""

import argparse
import shutil
from pathlib import Path
from dataclasses import dataclass
import cv2
import numpy as np
from tqdm import tqdm
from typing import List

# ============================================================================ 
# ‚öôÔ∏è –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –û–ë–†–ê–ë–û–¢–ö–ò
# ============================================================================ 

@dataclass
class ProcessingConfig:
    """–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø–∞–π–ø–ª–∞–π–Ω–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π."""
    # Bilateral Filter (—É–¥–∞–ª–µ–Ω–∏–µ —à—É–º–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫—Ä–∞–µ–≤)
    use_bilateral: bool = True
    bilateral_d: int = 5
    bilateral_sigma_color: int = 100
    bilateral_sigma_space: int = 80

    # Median Blur (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ —à—É–º–∞)
    use_median: bool = False
    median_ksize: int = 3

    # CLAHE (–ª–æ–∫–∞–ª—å–Ω–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞)
    clahe_clip_limit: float = 3.0
    clahe_grid_size: tuple[int, int] = (32, 32)

    # Gamma Correction (–∫–æ—Ä—Ä–µ–∫—Ü–∏—è —è—Ä–∫–æ—Å—Ç–∏)
    use_gamma: bool = True
    gamma_value: float = 1.60

    # Sharpening (–ø–æ–≤—ã—à–µ–Ω–∏–µ —Ä–µ–∑–∫–æ—Å—Ç–∏)
    use_sharpen: bool = True
    sharpen_alpha: float = 0.40

# ============================================================================ 
# üõ† –ü–ê–ô–ü–õ–ê–ô–ù –û–ë–†–ê–ë–û–¢–ö–ò
# ============================================================================ 

def apply_normalization_pipeline(
    image: np.ndarray, config: ProcessingConfig, clahe_processor: cv2.CLAHE
) -> np.ndarray:
    """
    –ü—Ä–∏–º–µ–Ω—è–µ—Ç –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ñ–∏–ª—å—Ç—Ä–æ–≤ –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏.
    """
    processed = image.copy()

    if config.use_bilateral:
        processed = cv2.bilateralFilter(
            processed, config.bilateral_d, config.bilateral_sigma_color, config.bilateral_sigma_space
        )
    if config.use_median:
        processed = cv2.medianBlur(processed, config.median_ksize)

    processed = clahe_processor.apply(processed)

    if config.use_gamma:
        table = np.array(
            [((i / 255.0) ** config.gamma_value) * 255 for i in np.arange(256)]
        ).astype("uint8")
        processed = cv2.LUT(processed, table)

    if config.use_sharpen:
        gaussian = cv2.GaussianBlur(processed, (0, 0), 3.0)
        processed = cv2.addWeighted(
            processed, 1.0 + config.sharpen_alpha, gaussian, -config.sharpen_alpha, 0
        )

    # Z-Score –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ 0-255
    processed_float = processed.astype(np.float32)
    mean, std = cv2.meanStdDev(processed_float)
    if std[0, 0] > 1e-6:
        processed_float = (processed_float - mean[0, 0]) / std[0, 0]

    return cv2.normalize(
        processed_float, None, 0, 255, cv2.NORM_MINMAX
    ).astype(np.uint8)

# ============================================================================ 
# üìÇ –õ–û–ì–ò–ö–ê –†–ê–ë–û–¢–´ –° –§–ê–ô–õ–ê–ú–ò
# ============================================================================ 

def process_single_file(
    img_path: Path, output_dir: Path, config: ProcessingConfig, clahe: cv2.CLAHE
):
    """–ß–∏—Ç–∞–µ—Ç, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."""
    image = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)
    if image is None:
        print(f"  [–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ] –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å: {img_path.name}")
        return

    normalized_image = apply_normalization_pipeline(image, config, clahe)
    output_path = output_dir / f"{img_path.stem}.png"
    cv2.imwrite(str(output_path), normalized_image)

def process_dataset_mode(
    input_dir: Path, output_dir: Path, config: ProcessingConfig, clahe: cv2.CLAHE
):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–æ—Ä–º–∞—Ç–µ YOLO (train/valid/test)."""
    print(f"üîπ –†–µ–∂–∏–º: Dataset. –û–±—Ä–∞–±–æ—Ç–∫–∞ {input_dir.name}...")
    for split in ["train", "valid", "test"]:
        input_img_dir = input_dir / "images" / split
        input_label_dir = input_dir / "labels" / split

        if not input_img_dir.is_dir(): # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
            continue

        print(f"  üìÇ –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–±–æ—Ä–∞ '{split}'...")
        output_img_dir = output_dir / "images" / split
        output_label_dir = output_dir / "labels" / split

        output_img_dir.mkdir(parents=True, exist_ok=True)
        output_label_dir.mkdir(parents=True, exist_ok=True)

        if input_label_dir.is_dir():
            shutil.copytree(input_label_dir, output_label_dir, dirs_exist_ok=True)

        image_paths = sorted(list(input_img_dir.glob("*.jpg")) + list(input_img_dir.glob("*.png")))
        for img_path in tqdm(image_paths, desc=f"  -> {split}"):
            process_single_file(img_path, output_img_dir, config, clahe)

def process_flat_mode(
    input_dir: Path, output_dir: Path, config: ProcessingConfig, clahe: cv2.CLAHE
):
    """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏."""
    print(f"üîπ –†–µ–∂–∏–º: Flat. –†–µ–∫—É—Ä—Å–∏–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ {input_dir}...")
    extensions = ["*.jpg", "*.jpeg", "*.png", "*.bmp", "*.tif"]
    image_paths = [p for ext in extensions for p in input_dir.rglob(ext)]

    if not image_paths:
        print(f"‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {input_dir}")
        return

    for img_path in tqdm(image_paths, desc="  -> –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"):
        relative_path = img_path.relative_to(input_dir)
        save_dir = output_dir / relative_path.parent
        save_dir.mkdir(parents=True, exist_ok=True)
        process_single_file(img_path, save_dir, config, clahe)

# ============================================================================ 
# üöÄ –ó–ê–ü–£–°–ö
# ============================================================================ 

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∏ –∑–∞–ø—É—Å–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
    parser = argparse.ArgumentParser(description="–°–∫—Ä–∏–ø—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.")
    parser.add_argument(
        "--mode", type=str, required=True, choices=["dataset", "flat"],
        help="–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã: 'dataset' –¥–ª—è YOLO-—Å—Ç—Ä—É–∫—Ç—É—Ä—ã, 'flat' –¥–ª—è –ø–∞–ø–∫–∏ —Å –∫–∞—Ä—Ç–∏–Ω–∫–∞–º–∏."
    )
    parser.add_argument(
        "--input", type=Path, required=True, help="–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏."
    )
    parser.add_argument(
        "--output", type=Path, required=True, help="–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏."
    )
    args = parser.parse_args()

    if not args.input.exists():
        print(f"‚ùå –û—à–∏–±–∫–∞: –í—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {args.input}")
        return

    if args.output.exists():
        shutil.rmtree(args.output)
    args.output.mkdir(parents=True)

    config = ProcessingConfig()
    clahe = cv2.createCLAHE(
        clipLimit=config.clahe_clip_limit, tileGridSize=config.clahe_grid_size
    )

    print(f"üöÄ –°—Ç–∞—Ä—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏: {args.input} -> {args.output}")
    print(f"‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: CLAHE={config.clahe_clip_limit}, Gamma={config.gamma_value}, Sharpen={config.sharpen_alpha}")

    if args.mode == "dataset":
        process_dataset_mode(args.input, args.output, config, clahe)
    elif args.mode == "flat":
        process_flat_mode(args.input, args.output, config, clahe)

    print("\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")

if __name__ == "__main__":
    main()